{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Package import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import Ipynb_importer\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Random minibatches</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    shuffle and partition\n",
    "    Returns:\n",
    "    mini_batches -- lis of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    np.random.random()\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    \n",
    "    # shuffle\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "    \n",
    "    # Partition\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    if m % mini_batch_size != 0: # handling with the end case\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Creat placeholders</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    n_x -- scalar, size of an image vertor (num_px * num_py * 3)\n",
    "    n_y -- scalar, number of classes\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input\n",
    "    Y -- placeholder for the data output\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None], name = \"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Initializing parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \"\"\"\n",
    "    parameters == {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W', str(l)] = tf.get_variable(\"W\" + str(l), [layer_dims[l], layer_dims[l - 1]], initializer = tf.contrib.layers.xavier_initializer())\n",
    "        parameters['b', str(l)] = tf.get_variable(\"W\" + str(l), [layer_dims[l], layer_dims[l - 1]], initializer = tf.zeros_initializer())\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Forward propagation in tf</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Linear -> Relu -> Linear -> Relu -> ... -> softmax\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters)\n",
    "    \n",
    "    Zs = {}\n",
    "    Activation = {}\n",
    "    Activation[\"A0\"] = X\n",
    "    for l in range(1, L):\n",
    "        Zs[\"Z\" + str(l)] = tf.add(tf.matmul(parameters[\"W\" + str(l)], Activation[\"A\" + str(l - 1)]), parameters[\"b\" + str(l)])\n",
    "        Activation[\"A\" + str(l)] = tf.nn.relu(Zs[\"Z\" + str(l)])\n",
    "    \n",
    "    Zs[\"Z\" + str(L)] = tf.add(tf.matmul(parameters[\"W\" + str(L)], Activation[\"A\" + str(L - 1)]), parameters[\"W\" + str(L)])\n",
    "    \n",
    "    return Zs[\"Z\" + str(L)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Compute cost</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(ZL, Y):\n",
    "    \n",
    "    logits = tf.transpose(ZL)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can be used to predict\n",
    "    \"\"\"\n",
    "    ops.reset_default_graph() # to be able to rerun the model without overwirting tf variables\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    \n",
    "    ZL = forward_propagation(X, parameters)\n",
    "    cost = compute(ZL, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            minibatches  = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feel_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "                epoch_cost += minibatch_cost/num_minibatches\n",
    "                \n",
    "            if(print_cost == True and epoch % 100 == 0):\n",
    "                    print(\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if(print_cost == True and epoch % 5 ==0):\n",
    "                    costs.append(epoch_cost)\n",
    "        # plot\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"Parameters have been trained!\")\n",
    "        # calculate accuracy on correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(ZL), tf.argmax(Y))\n",
    "        \n",
    "        # calculate the accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print(\"Traning accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Traning accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "    \n",
    "        return parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
